---
title: Benchmarks
description: Performance testing with real robotics workloads
order: 26
category: "internals"
---

# HORUS Benchmarks

**Performance validation** with real-world robotics workloads.

## Benchmark Methodology

### Measurement Approach
- **Statistical sampling**: Criterion.rs with 20+ samples per measurement
- **Confidence intervals**: Min/mean/max with outlier detection
- **Controlled methodology**: 1s warm-up, 5s measurement phases
- **Reproducible**: Less than 1% variance across measurements
- **Comprehensive coverage**: 5 workload types, 4 scalability points

### Workload Testing
- **Real workloads**: Control loops, sensor fusion, I/O operations
- **Fault injection**: Circuit breaker recovery testing
- **Scale testing**: Validated up to 200 concurrent nodes
- **Mixed patterns**: Combined blocking/non-blocking operations
- **Long-running**: 25+ second fault tolerance tests

## Executive Summary

**HORUS delivers sub-microsecond to low-microsecond latency for production robotics applications:**

| Message Type | Size | Latency (Hub) | Throughput | Typical Rate | Headroom |
|--------------|------|---------------|------------|--------------|----------|
| **CmdVel** | 16 B | **~500 ns** | 2.7M msg/s | 1000 Hz | 2,700x |
| **BatteryState** | 104 B | **~600 ns** | 1.67M msg/s | 1 Hz | 1.67M x |
| **IMU** | 304 B | **~940 ns** | 1.8M msg/s | 100 Hz | 18,000x |
| **Odometry** | 736 B | **~1.1 μs** | 1.3M msg/s | 50 Hz | 26,000x |
| **LaserScan** | 1.5 KB | **~2.2 μs** | 633K msg/s | 10 Hz | 63,300x |
| **PointCloud (1K)** | ~12 KB | **~12 μs** | 83K msg/s | 30 Hz | 2,767x |
| **PointCloud (10K)** | ~120 KB | **~360 μs** | 4.7K msg/s | 30 Hz | 157x |

<LatencyComparisonChart />


---

## Performance Highlights

### Key Findings

**Sub-microsecond latency** for messages up to 1.5KB
**Serde integration** works flawlessly with complex nested structs
**Linear scaling** with message size (predictable performance)
**Massive headroom** for all typical robotics frequencies

### Production Readiness

- **Real-time control**: ~500 ns latency supports 1000Hz+ control loops with 2,700x headroom
- **Sensor fusion**: Mixed workload maintains sub-microsecond performance (648 ns avg)
- **Perception pipelines**: 10K point clouds @ 30Hz with 189x headroom
- **Multi-robot systems**: Throughput supports 100+ robots on single node

---

## Detailed Results

### CmdVel (Motor Control Command)

**Use Case**: Real-time motor control @ 1000Hz
**Structure**: `{ timestamp: u64, linear: f32, angular: f32 }`

```
Average Latency: ~500 ns (Hub MPMC)
Throughput:      2.7M msg/s
Link SPSC:       248 ns median
```

**Analysis**: Sub-microsecond performance suitable for 1000Hz control loops with 2,700x headroom.

---

### LaserScan (2D Lidar Data)

**Use Case**: 2D lidar sensor data @ 10Hz
**Structure**: `{ ranges: [f32; 360], angle_min/max, metadata }`

```
Average Latency: ~2.2 μs (Hub MPMC)
Throughput:      633K msg/s
Link SPSC:       ~900 ns estimated
```

**Analysis**: Consistent low-microsecond latency for 1.5KB messages. Can easily handle 10Hz lidar updates with 63,300x headroom.

---

### IMU (Inertial Measurement Unit)

**Use Case**: Orientation and acceleration @ 100Hz
**Structure**: `{ orientation: [f64; 4], angular_velocity: [f64; 3], linear_acceleration: [f64; 3], covariances: [f64; 27] }`

```
Average Latency: ~940 ns (Hub MPMC)
Throughput:      1.8M msg/s
Link SPSC:       ~400 ns estimated
```

**Analysis**: Sub-microsecond performance with complex nested arrays and 27-element covariance matrices.

---

### Odometry (Pose + Velocity)

**Use Case**: Robot localization @ 50Hz
**Structure**: `{ pose: Pose2D, twist: Twist, pose_covariance: [f64; 36], twist_covariance: [f64; 36] }`

```
Average Latency: ~1.1 μs (Hub MPMC)
Throughput:      1.3M msg/s
Link SPSC:       ~600 ns estimated
```

**Analysis**: Low-microsecond latency for 736-byte messages with extensive covariance data.

---

### PointCloud (3D Perception)

#### Small (100 points @ 30Hz)
```
Average Latency: 1.85 μs
Throughput:      539,529 msg/s
Data Size:       ~1.2 KB
```

#### Medium (1,000 points @ 30Hz)
```
Average Latency: 7.55 μs
Throughput:      132,432 msg/s
Data Size:       ~12 KB
```

#### Large (10,000 points @ 30Hz)
```
Average Latency: ~360 μs (Hub MPMC)
Throughput:      4.7K msg/s
Data Size:       ~120 KB
```

**Analysis**: Linear scaling with point count. Even 10K point clouds process in ~360 μs (sufficient for 30Hz perception with 157x headroom).

---

### Mixed Workload (Realistic Robot Loop)

**Simulation**: Real robot control loop @ 100Hz
**Components**: CmdVel @ 100Hz + IMU @ 100Hz + BatteryState @ 1Hz

```
Total Operations: 20,100 messages
Average Latency:  ~1.0 μs (Hub MPMC)
Throughput:       ~1.5M msg/s
Range:            ~500-1200 ns
```

**Analysis**: Low-microsecond average latency for mixed message types simulating realistic robotics workload.

---

## Comparison with traditional frameworks

### Latency Comparison

> **Measurement Note**: Link values below are **send-only** (one-direction). For round-trip (send+receive), approximately double these values (e.g., 87ns send-only → ~175ns round-trip).

| Framework | Small Msg (send-only) | Medium Msg (send-only) | Large Msg (send-only) |
|-----------|-----------|------------|-----------|
| **HORUS Link (SPSC)** | **87 ns** | **~160 ns** | **~400 ns** |
| **HORUS Hub (MPMC)** | **313 ns** | **~500 ns** | **~1.1 μs** |
| ROS2 (DDS) | 50-100 μs | 100-500 μs | 1-10 ms |
| ROS2 (FastDDS) | 20-50 μs | 50-200 μs | 500 μs - 5 ms |

**Performance Advantage**: HORUS is **230-575x faster** than ROS2 for typical message sizes.

<SpeedupChart />

---

## Latency by Message Size

> **Measurement Note**: All latencies below are **send-only** (one-direction publish). Hub is lock-free MPMC, Link is wait-free SPSC.

| Message Size | Message Type | Hub (send-only) | Link (send-only) | vs ROS2 |
|-------------|--------------|-------------|--------------|---------|
| 16 B | CmdVel | ~313 ns | 87 ns | **230-575x faster** |
| 104 B | BatteryState | ~600 ns | ~350 ns | **83-286x faster** |
| 304 B | IMU | ~940 ns | ~400 ns | **53-250x faster** |
| 736 B | Odometry | ~1.1 μs | ~600 ns | **45-167x faster** |
| 1,480 B | LaserScan | ~2.2 μs | ~900 ns | **23-111x faster** |

**Observation**: Near-linear scaling with message size demonstrates efficient serialization and IPC.

<LatencyScalingChart />

---

## Python Benchmarks

HORUS provides comprehensive Python benchmarks that validate performance of the PyO3 bindings. Python performance is critical for robotics developers who need to integrate ML models, rapid prototyping, and high-level control logic.

### Python Performance Summary

| Message Type | Size | Avg Latency | Throughput | Notes |
|--------------|------|-------------|------------|-------|
| **CmdVel** | 16 B | **~5-10 μs** | 100K+ msg/s | Zero-copy via Rust core |
| **Pose2D** | 24 B | **~5-10 μs** | 100K+ msg/s | Type-safe bindings |
| **IMU** | 304 B | **~8-15 μs** | 80K+ msg/s | Complex nested arrays |
| **Odometry** | 736 B | **~10-20 μs** | 60K+ msg/s | Covariance matrices |
| **LaserScan** | 1.5 KB | **~15-30 μs** | 40K+ msg/s | Variable-length ranges |

<PythonThroughputChart />

### Python vs Alternatives

HORUS Python bindings significantly outperform traditional Python IPC mechanisms:

| Framework | Typical Latency | vs HORUS Python |
|-----------|-----------------|-----------------|
| **HORUS Python** | **~5-15 μs** | Baseline |
| Python multiprocessing.Queue | 100-200 μs | 10-40x slower |
| ROS2 rclpy | 100-500 μs | 20-100x slower |
| ZeroMQ (Python) | 50-100 μs | 5-20x slower |
| Redis pub/sub | 200-500 μs | 20-100x slower |

<PythonComparisonChart />

<PythonRustComparisonChart />

### Python Benchmark Suite

The Python benchmark suite includes four comprehensive tests:

#### IPC Latency Benchmark

Tests send-only and round-trip latency for all message types:

```python
from horus import Hub, CmdVel, Pose2D, Imu, Odometry, LaserScan

# Create typed hub (zero-copy shared memory)
hub = Hub(CmdVel)
msg = CmdVel(linear=1.5, angular=0.5)

# Measure send latency
hub.send(msg)  # ~5-10 μs

# Round-trip test
recv_hub = Hub(CmdVel)
hub.send(msg)
received = recv_hub.recv()  # ~10-20 μs round-trip
```

#### Throughput Benchmark

Measures maximum sustainable throughput by message size:

```python
# Small messages (CmdVel 16B): 100K+ msg/s
# Medium messages (IMU 304B): 80K+ msg/s
# Large messages (LaserScan 1.5KB): 40K+ msg/s
```

#### Stress Test Benchmark

Validates stability under heavy load:

- **Single-thread sustained**: 5+ second continuous operation
- **Multi-thread concurrent**: 2, 4, 8 thread writers
- **Burst testing**: 10x bursts of 10K messages
- **Mixed messages**: CmdVel + Pose2D + IMU interleaved

<PythonStressChart />

#### Comparison Benchmark

Direct comparison against Python alternatives:

```python
# Tests run:
# 1. HORUS typed Hub (zero-copy)
# 2. Python multiprocessing.Queue (pickle)
# 3. Python shared_memory (manual struct.pack)
# 4. pickle serialization overhead
# 5. ZeroMQ inproc (optional)
# 6. Redis pub/sub (optional)
```

### Running Python Benchmarks

#### Prerequisites

```bash
# Install HORUS Python bindings
cd horus_py
maturin develop --release

# Optional: Install comparison frameworks
pip install pyzmq redis
```

#### Run All Benchmarks

```bash
# Full benchmark suite
python -m horus_py.benchmarks.run_all

# Quick mode (fewer iterations)
python -m horus_py.benchmarks.run_all --quick

# JSON output
python -m horus_py.benchmarks.run_all --json

# Save results
python -m horus_py.benchmarks.run_all --output results.json
```

#### Run Individual Benchmarks

```bash
# IPC latency
python -m horus_py.benchmarks.ipc_latency

# Throughput
python -m horus_py.benchmarks.throughput

# Stress test
python -m horus_py.benchmarks.stress_test

# Comparison vs alternatives
python -m horus_py.benchmarks.comparison
```

### Expected Python Output

```
======================================================================
  HORUS Python IPC Latency Benchmark Suite
  Testing with real robotics message types
======================================================================

----------------------------------------------------------------------
  CmdVel (Motor Control Command)
  Use case: Real-time motor control @ 1000Hz
----------------------------------------------------------------------

  CmdVel send (typed, zero-copy)
    Message Size: 16 bytes
    Iterations:   10,000
    Latency (avg): 6.23 μs
    Latency (p50): 5.89 μs
    Latency (p95): 8.12 μs
    Latency (p99): 12.34 μs
    Throughput:    160,514 ops/sec

  CmdVel round-trip (send + recv)
    Message Size: 16 bytes
    Iterations:   1,000
    Latency (avg): 12.45 μs
    Latency (p50): 11.23 μs
    Throughput:    80,321 ops/sec
```

### Python Performance Notes

**Why Python HORUS is Fast:**

1. **Zero-copy via Rust core**: Python bindings call directly into Rust shared memory
2. **No pickle overhead**: Messages use efficient binary serialization
3. **PyO3 efficiency**: Minimal FFI overhead between Python and Rust
4. **Type-safe messages**: Compile-time message validation in Rust

**Robotics Use Cases:**

| Use Case | Target Rate | Python Capacity | Headroom |
|----------|-------------|-----------------|----------|
| Motor control | 1000 Hz | 100K+ Hz | 100x |
| IMU fusion | 200 Hz | 80K+ Hz | 400x |
| Odometry | 100 Hz | 60K+ Hz | 600x |
| LiDAR SLAM | 20 Hz | 40K+ Hz | 2000x |
| Dense LiDAR | 10 Hz | 30K+ Hz | 3000x |

**Python + Rust Interoperability:**

```python
# Python node sends to Rust node (same shared memory!)
from horus import Hub, CmdVel

# Python publisher
pub = Hub(CmdVel)
pub.send(CmdVel(linear=1.0, angular=0.5))

# Rust subscriber receives instantly (zero-copy)
# Both use the same /dev/shm/horus/topics/CmdVel
```

### TensorPool Benchmarks

HORUS TensorPool provides shared memory tensors optimized for ML/AI workloads. These benchmarks show Python performance for tensor operations.

#### TensorPool vs NumPy Allocation

| Tensor Size | TensorPool | np.zeros() | Speedup |
|-------------|------------|------------|---------|
| 64×64 (16 KB) | **5.7 μs** | 9.6 μs | **1.7×** |
| 256×256 (256 KB) | **4.5 μs** | 35 μs | **8×** |
| 512×512 (1 MB) | **8.5 μs** | ~150 μs | **18×** |
| 1024×1024 (4 MB) | **~10 μs** | 637 μs | **64×** |

**Why TensorPool is faster:** Pre-mapped shared memory means no `malloc()` or zero-initialization on the hot path.

#### TensorPool Operations

| Operation | Latency | Throughput | Notes |
|-----------|---------|------------|-------|
| `pool.alloc([256, 256], 'float32')` | **4.5 μs** | 224K ops/s | Bump allocator |
| `.numpy()` zero-copy view | **15 μs** | 68K ops/s | Creates NumPy view |
| `.view([1048576])` reshape | **3.4 μs** | 291K ops/s | Metadata only |
| `.slice(0, 512)` | **3.8 μs** | 265K ops/s | First-dim slice |

#### Memory Copy Performance (memcpy into shared memory)

| Size | Latency | Bandwidth |
|------|---------|-----------|
| 16 KB (64×64) | 30 μs | 533 MB/s |
| 256 KB (256×256) | 67 μs | 3.8 GB/s |
| 4 MB (1024×1024) | 2.1 ms | 1.9 GB/s |

#### Running TensorPool Benchmarks

```python
from horus import TensorPool
import numpy as np
import time

# Create pool (unique ID avoids stale data)
pool = TensorPool(12345)  # pool_id

# Allocate tensor
h = pool.alloc([1024, 1024], 'float32')

# Zero-copy NumPy view
arr = h.numpy()  # ~15 μs, no data copied

# Write data (actual memcpy)
data = np.random.rand(1024, 1024).astype(np.float32)
np.copyto(arr, data)  # ~2 ms for 4MB

# Cross-process sharing
descriptor = h.to_descriptor()  # Share with other processes
```

**Key Advantages:**
- **Cross-process sharing** via `/dev/shm`
- **Pre-allocated pool** - no malloc on hot path
- **Refcounted handles** - safe concurrent access
- **Zero-copy NumPy** - `.numpy()` returns view
- **CUDA support** - `.cuda()` for GPU tensors

---

## Running Rust Benchmarks

### Quick Run

```bash
cd horus
cargo build --release --bin ipc_benchmark
./target/release/ipc_benchmark
```

### Expected Output

```

  HORUS Production Message Benchmark Suite
  Testing with real robotics message types


  CmdVel (Motor Control Command)
    Size: 16 bytes | Typical rate: 1000Hz
    Latency (avg): ~500 ns (Hub) / 248 ns (Link)
    Throughput: 2.7M msg/s (Hub)


  LaserScan (2D Lidar Data)
    Size: 1480 bytes | Typical rate: 10Hz
    Latency (avg): ~2.2 μs (Hub) / ~900 ns (Link)
    Throughput: 633K msg/s (Hub)

```

---

## Use Case Selection

### Message Type Guidelines

**CmdVel (~500 ns Hub / 248 ns Link)**
- Motor control @ 1000Hz
- Real-time actuation commands
- Safety-critical control loops

**IMU (~940 ns Hub / ~400 ns Link)**
- High-frequency sensor fusion @ 100Hz
- State estimation pipelines
- Orientation tracking

**LaserScan (~2.2 μs Hub / ~900 ns Link)**
- 2D lidar @ 10Hz
- Obstacle detection
- SLAM front-end

**Odometry (~1.1 μs Hub / ~600 ns Link)**
- Pose estimation @ 50Hz
- Dead reckoning
- Filter updates

**PointCloud (~360 μs for 10K pts)**
- 3D perception @ 30Hz
- Object detection pipelines
- Dense mapping

---

## Performance Characteristics

### Strengths

1. **Sub-microsecond latency** for messages up to 1.5KB
2. **Consistent performance** across message types (low variance)
3. **Linear scaling** with message size
4. **Production-ready** throughput with large headroom
5. **Serde integration** handles complex nested structs efficiently

### Technical Details

- **Serde overhead**: ~200-300ns compared to raw transfers
- **Complex structs** (IMU with 27-element covariances): Still sub-microsecond
- **Variable-size messages** (PointCloud with Vec): Linear scaling

---

## Real-World Applications

| Application | Frequency | HORUS (Link) | HORUS (Hub) | ROS2 | Speedup |
|-------------|-----------|--------------|-------------|------|---------|
| Motor control | 1000 Hz | 248 ns | ~500 ns | 50 μs | **100-202x** |
| IMU fusion | 100 Hz | ~400 ns | ~940 ns | 50 μs | **53-125x** |
| Lidar SLAM | 10 Hz | ~900 ns | ~2.2 μs | 100 μs | **45-111x** |
| Vision | 30 Hz | ~120 μs | ~360 μs | 5 ms | **14-42x** |
| Planning | 100 Hz | ~600 ns | ~1.1 μs | 100 μs | **91-167x** |

<ThroughputChart />

---

## Methodology

### Benchmark Pattern: Ping-Pong

**HORUS uses the industry-standard ping-pong benchmark pattern for IPC latency measurement:**

<MermaidDiagram
  chart={`%%{init: {'sequence': {'padding': 15}}}%%
sequenceDiagram
    participant P as Producer (Core 0)
    participant C as Consumer (Core 1)

    P->>C: 1. Send message with RDTSC
    Note right of C: 2. Read RDTSC, calc latency
    C->>P: 3. Send ACK
    Note left of P: 4. Wait for ACK
    P->>C: 5. Send next message
`}
  caption="Ping-Pong Benchmark Pattern"
/>

**Why Ping-Pong?**
- **Industry standard**: Used by ROS2, iceoryx2, ZeroMQ benchmarks
- **Prevents queue buildup**: Each message acknowledged before next send
- **Realistic**: Models request-response patterns in robotics
- **Comparable**: Direct apples-to-apples comparison with other frameworks
- **Conservative**: Measures true round-trip latency, not just one-way send

**What we measure:**
- Round-trip time: Producer  Consumer  ACK  Producer
- Includes serialization, IPC, deserialization, and synchronization
- Cross-core communication (Core 0 ↔ Core 1)

**What we DON'T measure:**
- Burst throughput (no backpressure)
- One-way send time without acknowledgment
- Same-core communication (unrealistic for multi-process IPC)

### Test Environment

- **Build**: `cargo build --release` with full optimizations
- **CPU Governor**: Performance mode
- **CPU Affinity**: Producer pinned to Core 0, Consumer pinned to Core 1
- **Process Isolation**: Dedicated topics per benchmark
- **Warmup**: 1,000 iterations before measurement
- **Measurement**: RDTSC (cycle-accurate timestamps)

### Message Realism

- Actual HORUS library message types
- Serde serialization (production path)
- Realistic field values and sizes
- Complex nested structures (IMU, Odometry)

### Statistical Methodology

- 10,000 iterations per test
- Median, P95, P99 latency tracking
- Variance tracking (min/max ranges)
- Multiple message sizes
- Mixed workload testing

### Measurement Details

**RDTSC Calibration:**
- Null cost (back-to-back rdtsc): ~36 cycles
- Target on modern x86_64: 20-30 cycles
- Timestamp embedded directly in message payload

**Cross-Core Testing:**
- Producer and consumer on different CPU cores
- Simulates real multi-process robotics systems
- Includes cache coherency overhead (~60 cycles theoretical minimum)

---

## Scheduler Performance

### Enhanced Smart Scheduler

HORUS now includes an intelligent scheduler that automatically optimizes node execution based on runtime behavior:

**Key Enhancements:**
- **JIT Compilation**: Hot paths compiled to native code using Cranelift
- **Async I/O Tier**: Non-blocking execution for I/O-heavy operations
- **Fault Tolerance**: Circuit breaker pattern with automatic recovery
- **Smart Classification**: 5-tier automatic categorization based on profiling
- **Zero Configuration**: All optimizations happen automatically

### Comprehensive Benchmark Results

**Test Configuration:**
- Workload duration: 5 seconds per test
- Sample size: 20 measurements per benchmark
- Platform: Modern x86_64 Linux system

| Workload Type | Mean Time | Description | Key Achievement |
|---------------|-----------|-------------|-----------------|
| **UltraFastControl** | **2.387s** | High-frequency control loops | Optimized for high-frequency control |
| **FastSensor** | **2.382s** | Rapid sensor processing | Maintains sub-μs sensor fusion |
| **HeavyIO** | **3.988s** | I/O-intensive operations | Async tier prevents blocking |
| **MixedRealistic** | **4.064s** | Real-world mixed workload | Balanced optimization across tiers |
| **FaultTolerance** | **25.485s** | With simulated failures | Circuit breaker recovery working |

### Scalability Performance

The scheduler demonstrates excellent linear scaling:

| Node Count | Execution Time | Scaling Factor |
|------------|---------------|----------------|
| 10 nodes | **106.93ms** | Baseline |
| 50 nodes | **113.93ms** | 1.07x (5x nodes) |
| 100 nodes | **116.49ms** | 1.09x (10x nodes) |
| 200 nodes | **119.55ms** | 1.12x (20x nodes) |

**Key Insights:**
- Near-linear scaling from 10 to 200 nodes
- Only 13ms increase for 20x more nodes
- Maintains sub-120ms for large systems
- Automatic tier classification optimizes execution order

<ScalabilityChart />

---

## Real-Time Performance

### RtNode Support

HORUS now provides industrial-grade real-time support for safety-critical applications:

**RT Features:**
- **WCET Enforcement**: Worst-Case Execution Time monitoring
- **Deadline Tracking**: Hard/Firm/Soft real-time classes
- **Safety Monitor**: Emergency stop on critical failures
- **Watchdog Timers**: Detect hung or crashed nodes
- **Priority Inheritance**: Prevent priority inversion

### RT Performance Characteristics

| Metric | Performance | Description |
|--------|-------------|-------------|
| **WCET Overhead** | **&lt;5μs** | Cost of monitoring execution time |
| **Deadline Precision** | **±10μs** | Jitter in deadline detection |
| **Watchdog Resolution** | **1ms** | Minimum detection time |
| **Emergency Stop** | **&lt;100μs** | Time to halt all nodes |
| **Context Switch** | **&lt;1μs** | Priority preemption overhead |

### Safety-Critical Configuration

Running with full safety monitoring enabled:

```rust
scheduler.set_config(SchedulerConfig::safety_critical());
```

| Feature | Overhead | Impact |
|---------|----------|--------|
| WCET Tracking | ~1μs per node | Negligible for &gt;100μs tasks |
| Deadline Monitor | ~500ns per node | Sub-microsecond overhead |
| Watchdog Feed | ~100ns per tick | Minimal impact |
| Safety Checks | ~2μs total | Worth it for safety |
| Memory Locking | One-time 10ms | Prevents page faults |

### Real-Time Test Results

**Test: Mixed RT and Normal Nodes**
- 2 critical RT nodes @ 1kHz
- 2 normal nodes @ 100Hz
- 2 background nodes @ 10Hz

| Node Type | Target Rate | Achieved | Jitter | Misses |
|-----------|------------|----------|--------|--------|
| RT Critical | 1000 Hz | 999.8 Hz | ±10μs | 0 |
| RT High | 500 Hz | 499.9 Hz | ±15μs | 0 |
| Normal | 100 Hz | 99.9 Hz | ±50μs | &lt;0.1% |
| Background | 10 Hz | 10 Hz | ±200μs | &lt;0.5% |

**Zero deadline misses** for critical RT nodes over 1M iterations.

<RealTimeChart />

---

## Summary

**HORUS provides production-grade performance for real robotics applications:**

**Link (SPSC) - Point-to-Point (Wait-Free):**
- **87 ns** - Send only (ultra-low latency)
- **161 ns** - CmdVel (motor control)
- **262 ns** - Send+Recv round-trip
- **~400 ns** - IMU (sensor fusion)
- **~120 μs** - PointCloud with 10K points

**Hub (MPMC) - Pub/Sub (Lock-Free):**
- **~313 ns** - CmdVel (motor control)
- **~500 ns** - IMU (sensor fusion)
- **~2.2 μs** - LaserScan (2D lidar)
- **~1.1 μs** - Odometry (localization)
- **~360 μs** - PointCloud with 10K points


**Ready for production deployment** in demanding robotics applications requiring real-time performance with complex data types.

---

## Next Steps

- Learn how to maximize performance: [Performance Optimization](/performance/performance)
- Explore message types: [Message Types](/concepts/message-types)
- See usage examples: [Examples](/rust/examples/basic-examples)
- Get started: [Quick Start](/getting-started/quick-start)

**Build faster. Debug easier. Deploy with confidence.** 
